# Robotic Locomotion
- arXiv 2023.11, **GOAT**: GO to Any Thing, [Website](https://theophilegervet.github.io/projects/goat/)
- ICRA 2024 submission, Visual **Manipulation with Legs**, [Website](https://hacleg.github.io/)
- arXiv 2023.10, **Grow Your Limits**: Continuous Improvement with Real-World RL for Robotic Locomotion, [Website](https://github.com/realquantumcookie/APRL) / [arXiv](https://arxiv.org/abs/2310.17634)
- arXiv 2023.09, Learning Vision-Based Bipedal Locomotion for Challenging Terrain, [arXiv](https://arxiv.org/abs/2309.14594) / [Twitter](https://x.com/AlanPaulFern1/status/1709693615973265733?s=20)
- arXiv 2023.10, **Generalized Animal Imitator**: Agile Locomotion with Versatile Motion Prior, [Website](https://rchalyang.github.io/VIM/) / [arXiv](https://arxiv.org/abs/2310.01408)
- arXiv 2023.09, **CrossLoco**: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning, [arXiv](https://arxiv.org/abs/2309.17046)
- RA-L 2024, **SLoMo**: A General System for Legged Robot Motion Imitation from Casual Videos, [Website](https://slomo-www.github.io/website/) / [arXiv](https://arxiv.org/abs/2304.14389)
- arXiv 2023.09, Extreme Parkour with Legged Robots, [Website](https://extreme-parkour.github.io/) / [arXiv](https://arxiv.org/abs/2309.14341)
- arXiv 2023.09, Prompt a Robot to Walk with Large Language Models, [arXiv](https://arxiv.org/abs/2309.09969) / [Website](https://prompt2walk.github.io/)
- arXiv 2023.08, Learning Vision-based Pursuit-Evasion Robot Policies, [Website](https://abajcsy.github.io/vision-based-pursuit/) / [arXiv](https://arxiv.org/abs/2308.16185)
- arXiv 2023.05, **Barkour**: Benchmarking Animal-level Agility with Quadruped Robots, [arXiv](https://arxiv.org/abs/2305.14654)
- CoRL 2023 oral, Robot Parkour Learning, [Website](https://robot-parkour.github.io/) / [Github](https://github.com/ZiwenZhuang/parkour)
- RSS 2023, Robust and Versatile Bipedal Jumping Control through Reinforcement Learning, [arXiv](https://arxiv.org/abs/2302.09450)
- arXiv 2023, **DribbleBot**: Dynamic Legged Manipulation in the Wild, [Website](https://gmargo11.github.io/dribblebot/)
- arXiv 2023, Learning Humanoid Locomotion with Transformers, [Website](https://humanoid-transformer.github.io/)
- ICLR 2022, **LocoTransformer**: Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers, [Website](https://rchalyang.github.io/LocoTransformer/) / [Github](https://github.com/Mehooz/vision4leg)
- CoRL 2022, **Walk These Ways**: Tuning Robot Control for Generalization with Multiplicity of Behavior, [Github](https://github.com/Improbable-AI/walk-these-ways) / [Website](https://gmargo11.github.io/walk-these-ways/)
- CoRL 2022 Best Paper Award Finalist, Learning Agile Skills via Adversarial Imitation of Rough Partial Demonstrations, [Website](https://sites.google.com/view/corl2022-wasabi/home) / [Github](https://github.com/martius-lab/wasabi)
- CoRL 2022 best system paper, Legged Locomotion in Challenging Terrains using Egocentric Vision, [Website](https://vision-locomotion.github.io/)
- CoRL 2022 oral, **Deep Whole-Body Control**: Learning a Unified Policy for Manipulation and Locomotion, [Website](https://manipulation-locomotion.github.io/)
- RSS 2022, Rapid Locomotion via Reinforcement Learning, [Website](https://agility.csail.mit.edu/) / [Github](https://github.com/Improbable-AI/rapid-locomotion-rl)
- RSS 2021, **RMA**: Rapid Motor Adaptation for Legged Robots, [Website](https://ashish-kmr.github.io/rma-legged-robots/) /  [Github](https://github.com/antonilo/rl_locomotion)
- CoRL 2021, Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning, [Website](https://leggedrobotics.github.io/legged_gym/) / [Github](https://github.com/leggedrobotics/legged_gym)
- RSS 2020 best paper award, Learning Agile Robotic Locomotion Skills by Imitating Animals, [Website](https://xbpeng.github.io/projects/Robotic_Imitation/index.html) / [Github](https://github.com/erwincoumans/motion_imitation)
