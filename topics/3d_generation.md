# 3D Generation
- arXiv 2023.10, **HyperFields**: Towards Zero-Shot Generation of NeRFs from Text, [Website](https://threedle.github.io/hyperfields/) / [arXiv](https://arxiv.org/abs/2310.17075)
- arXiv 2023.10, **Zero123++**: a Single Image to Consistent Multi-view Diffusion Base Model, [Github](https://github.com/SUDO-AI-3D/zero123plus) / [arXiv](https://arxiv.org/abs/2310.15110)
- ICLR 2024 submission, **Instant3D**: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model, [Website](https://instant-3d.github.io/)
- ICLR 2024 submission, **LRM**: Large Reconstruction Model for Single Image to 3D, [Website](https://scalei3d.github.io/LRM/)
- arXiv 2023.09, **DreamGaussian**: Generative Gaussian Splatting for Efficient 3D Content Creation, [Website](https://dreamgaussian.github.io/) / [GitHub 1.9k](https://github.com/dreamgaussian/dreamgaussian)
- SIGGRAPH Asia 2023, **Rerender A Video**: Zero-Shot Text-Guided Video-to-Video Translation, [Github 2.4k](https://github.com/williamyang1991/Rerender_A_Video)
- arXiv 2023.06, **Magic123**: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors, [Github 1.2k](https://github.com/guochengqian/Magic123)
- NeurIPS 2023, **One-2-3-45**: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization, [Github 1k](https://github.com/One-2-3-45/One-2-3-4)
- ICCV 2023, **Zero-1-to-3**: Zero-shot One Image to 3D Object, [Github 1.8k](https://github.com/cvlab-columbia/zero123)
- ICLR 2023 outstanding paper, **DreamFusion**: Text-to-3D using 2D Diffusion, [Website](https://dreamfusion3d.github.io/) / [Github 6.9k](https://github.com/ashawkey/stable-dreamfusion)
