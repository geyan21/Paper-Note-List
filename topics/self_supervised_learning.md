# Self-Supervised Learning
- [Self-Supervised Learning](#self-supervised-learning)
  - [Autoencoders](#autoencoders)
  - [Visual Prompting](#visual-prompting)
  - [Contrastive Learning](#contrastive-learning)
  - [3D Vision](#3d-vision)
  - [Correspondence](#correspondence)
  - [Vision-Language](#vision-language)
  - [New Paradigms](#new-paradigms)


## Autoencoders
- CVPR 2022, [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
- NIPS 2017, VQ-VAE: [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
- NIPS 2016, VGAE: [Variational Graph Auto-Encoders](https://arxiv.org/abs/1611.07308)

## Visual Prompting
-  NIPS 2022, [Visual Prompting via Image Inpainting](https://yossigandelsman.github.io/visual_prompt/)
-  arXiv 2022, [Exploring Visual Prompts for Adapting Large-Scale Models](https://hjbahng.github.io/visual_prompting/)

## Contrastive Learning
- arXiv 2022, [InternVideo: General Video Foundation Models via Generative and Discriminative Learning](https://arxiv.org/abs/2212.03191)
- CVPR 2021, DINO: [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)
- ICML 2021, DeiT: [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
- arXiv 2020, MoCov2: [Improved Baselines with Momentum Contrastive Learning](https://arxiv.org/abs/2003.04297)
- CVPR 2020, MoCo: [Momentum Contrast for Unsupervised Visual Representation Learning](https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)
- NIPS 2020, SwAV: [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882)
- ECCV 2020, [PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding](https://arxiv.org/abs/2007.10985)


## 3D Vision
- NIPS 2022, [CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion](https://croco.europe.naverlabs.com/public/index.html)
- ICCV 2021, [Pri3D: Can 3D Priors Help 2D Representation Learning?](https://arxiv.org/abs/2104.11225)

## Correspondence
- ICLR 2023, [Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild](https://kywind.github.io/self-pose)
- arXiv 2021, [Deep ViT Features as Dense Visual Descriptors](https://dino-vit-features.github.io/)
- ICCV 2021, [The Functional Correspondence Problem](https://agi-labs.github.io/FuncCorr/)
- arXiv 2020, [Keypoints into the future: Self-supervised correspondence in model-based reinforcement learning](https://arxiv.org/abs/2009.05085)
- NIPS 2020, [Space-Time Correspondence as a Contrastive Random Walk](https://ajabri.github.io/videowalk/)
- CVPR 2020, [Self-supervised Learning of Interpretable Keypoints from Unlabelled Videos](https://www.robots.ox.ac.uk/vgg/research/unsupervised_pose/)
- CVPR 2019, [Learning Correspondence from the Cycle-Consistency of Time](https://ajabri.github.io/timecycle/)
- NIPS 2018, [Unsupervised Learning of Object Landmarks through Conditional Image Generation](https://www.robots.ox.ac.uk/~vgg/research/unsupervised_landmarks/)
- ECCV 2018, [Videos as Space-Time Region Graphs](https://arxiv.org/abs/1806.01810v2)

## Vision-Language
- arXiv 2022, [PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning](https://arxiv.org/abs/2211.11682)
- CVPR 2022, [PointCLIP: Point Cloud Understanding by CLIP](https://arxiv.org/abs/2112.02413)
- ICML 2021, CLIP: [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- NIPS 2022, [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)

## New Paradigms
- NIPS 2022, [Visual Pre-training for Navigation: What Can We Learn from Noise?](https://yanweiw.github.io/noise2ptz/)
- NIPS 2021, [MarioNette: Self-Supervised Sprite Learning](https://people.csail.mit.edu/smirnov/marionette/)
- NIPS 2020, [Object-Centric Learning with Slot Attention](https://arxiv.org/abs/2006.15055)
